# RAMate Backend Configuration
# Copy this file to .env and fill in your API keys

# Required: OpenRouter API key for AI inference
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Optional: Model configuration (defaults provided)
AI_MODEL=deepseek/deepseek-chat-v3-0324:free
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Optional: Database configuration
CHROMA_PERSIST_DIRECTORY=./chroma_store
VECTOR_COLLECTION_NAME=ramate_documents

# Optional: API server configuration
FLASK_PORT=5000
FLASK_DEBUG=True
CORS_ORIGINS=http://localhost:3000

# Optional: Processing configuration
PDF_DIRECTORY=../pdfs
CHUNK_SIZE=600
CHUNK_OVERLAP=100
MAX_RETRIEVAL_RESULTS=3

# Optional: Performance tuning
MAX_TOKENS=800
TEMPERATURE=0.3
REQUEST_TIMEOUT=30

# Optional: Development tools
NGROK_AUTH_TOKEN=your_ngrok_token_here
